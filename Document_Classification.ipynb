{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Document Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ja59AaFws5n",
        "colab_type": "text"
      },
      "source": [
        "# graph regularization for document classification using natural graphs\n",
        "_________________________________\n",
        "https://www.tensorflow.org/neural_structured_learning/tutorials/graph_keras_mlp_cora"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxp7LvUvwmnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "84904412-6a3d-407a-f22b-c28f6952526a"
      },
      "source": [
        "# setup\n",
        "!pip install --quiet tensorflow==2.0.0-rc0\n",
        "!pip install --quiet neural-structured-learning"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 86.3MB 1.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 42.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.3MB 42.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 501kB 57.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 4.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 4.2MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJjLblbOxIW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b5a69d3e-a065-4130-dc3c-4bf46c1c5df1"
      },
      "source": [
        "# dependencies and imports\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import neural_structured_learning as nsl\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# reset notebook state\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "print(\"Version: \", tf.__version__)\n",
        "print(\"Eager mode: \", tf.executing_eagerly())\n",
        "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Version:  2.0.0-rc0\n",
            "Eager mode:  True\n",
            "GPU is NOT AVAILABLE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uTpl6n6zhMu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "889f1600-152d-4a1b-cc2d-142a2609b16f"
      },
      "source": [
        "!wget --quiet -P /tmp https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\n",
        "!tar -C /tmp -xvzf /tmp/cora.tgz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cora/\n",
            "cora/README\n",
            "cora/cora.content\n",
            "cora/cora.cites\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Qe5Amv3zxKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "c593b6d5-b61b-4cc1-e696-b01e6943893d"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
        "\n",
        "!python preprocess_cora_dataset.py \\\n",
        "--input_cora_content=/tmp/cora/cora.content \\\n",
        "--input_cora_graph=/tmp/cora/cora.cites \\\n",
        "--max_nbrs=5 \\\n",
        "--output_train_data=/tmp/cora/train_merged_examples.tfr \\\n",
        "--output_test_data=/tmp/cora/test_examples.tfr"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-09-13 12:47:39--  https://raw.githubusercontent.com/tensorflow/neural-structured-learning/master/neural_structured_learning/examples/preprocess/cora/preprocess_cora_dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7327 (7.2K) [text/plain]\n",
            "Saving to: ‘preprocess_cora_dataset.py’\n",
            "\n",
            "\r          preproces   0%[                    ]       0  --.-KB/s               \rpreprocess_cora_dat 100%[===================>]   7.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-09-13 12:47:39 (109 MB/s) - ‘preprocess_cora_dataset.py’ saved [7327/7327]\n",
            "\n",
            "Reading graph file: /tmp/cora/cora.cites...\n",
            "Done reading 5429 edges from: /tmp/cora/cora.cites (0.01 seconds).\n",
            "Making all edges bi-directional...\n",
            "Done (0.01 seconds). Total graph nodes: 2708\n",
            "Joining seed and neighbor tf.train.Examples with graph edges...\n",
            "Done creating and writing 2155 merged tf.train.Examples (1.45 seconds).\n",
            "Out-degree histogram: [(1, 386), (2, 468), (3, 452), (4, 309), (5, 540)]\n",
            "Output training data written to TFRecord file: /tmp/cora/train_merged_examples.tfr.\n",
            "Output test data written to TFRecord file: /tmp/cora/test_examples.tfr.\n",
            "Total running time: 0.04 minutes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1f3RUQnxumA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global Variables\n",
        "### Experiment dataset\n",
        "TRAIN_DATA_PATH = '/tmp/cora/train_merged_examples.tfr'\n",
        "TEST_DATA_PATH = '/tmp/cora/test_examples.tfr'\n",
        "\n",
        "### Constants used to identify neighbor features in the input.\n",
        "NBR_FEATURE_PREFIX = 'NL_nbr_'\n",
        "NBR_WEIGHT_SUFFIX = '_weight'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRfhM6ud0JlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "class HParams(object):\n",
        "  \"\"\"Hyperparameters used for training.\"\"\"\n",
        "  def __init__(self):\n",
        "    ### dataset parameters\n",
        "    self.num_classes = 7\n",
        "    self.max_seq_length = 1433\n",
        "    ### neural graph learning parameters\n",
        "    self.distance_type = nsl.configs.DistanceType.L2\n",
        "    self.graph_regularization_multiplier = 0.1\n",
        "    self.num_neighbors = 1\n",
        "    ### model architecture\n",
        "    self.num_fc_units = [50, 50]\n",
        "    ### training parameters\n",
        "    self.train_epochs = 100\n",
        "    self.batch_size = 128\n",
        "    self.dropout_rate = 0.5\n",
        "    ### eval parameters\n",
        "    self.eval_steps = None # All instances in the test set are evaluated.\n",
        "\n",
        "HPARAMS = HParams()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFOi_Ip-1eQo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_example(example_proto):\n",
        "  \"\"\"Extracts relevant fields from the `example_proto`.\n",
        "\n",
        "  Args:\n",
        "    example_proto: An instance of `tf.train.Example`.\n",
        "\n",
        "  Returns:\n",
        "    A pair whose first value is a dictionary containing relevant features\n",
        "    and whose second value contains the ground truth labels.\n",
        "  \"\"\"\n",
        "  # The 'words' feature is a multi-hot, bag-of-words representation of the\n",
        "  # original raw text. A default value is required for examples that don't\n",
        "  # have the feature.\n",
        "  feature_spec = {\n",
        "      'words':\n",
        "          tf.io.FixedLenFeature([HPARAMS.max_seq_length],\n",
        "                                tf.int64,\n",
        "                                default_value=tf.constant(\n",
        "                                    0,\n",
        "                                    dtype=tf.int64,\n",
        "                                    shape=[HPARAMS.max_seq_length])),\n",
        "      'label':\n",
        "          tf.io.FixedLenFeature((), tf.int64, default_value=-1),\n",
        "  }\n",
        "  # We also extract corresponding neighbor features in a similar manner to\n",
        "  # the features above.\n",
        "  for i in range(HPARAMS.num_neighbors):\n",
        "    nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, i, 'words')\n",
        "    nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, i, NBR_WEIGHT_SUFFIX)\n",
        "    feature_spec[nbr_feature_key] = tf.io.FixedLenFeature(\n",
        "        [HPARAMS.max_seq_length],\n",
        "        tf.int64,\n",
        "        default_value=tf.constant(\n",
        "            0, dtype=tf.int64, shape=[HPARAMS.max_seq_length]))\n",
        "\n",
        "    # We assign a default value of 0.0 for the neighbor weight so that\n",
        "    # graph regularization is done on samples based on their exact number\n",
        "    # of neighbors. In other words, non-existent neighbors are discounted.\n",
        "    feature_spec[nbr_weight_key] = tf.io.FixedLenFeature(\n",
        "        [1], tf.float32, default_value=tf.constant([0.0]))\n",
        "\n",
        "  features = tf.io.parse_single_example(example_proto, feature_spec)\n",
        "\n",
        "  labels = features.pop('label')\n",
        "  return features, labels\n",
        "\n",
        "\n",
        "def make_dataset(file_path, training=False):\n",
        "  \"\"\"Creates a `tf.data.TFRecordDataset`.\n",
        "\n",
        "  Args:\n",
        "    file_path: Name of the file in the `.tfrecord` format containing\n",
        "      `tf.train.Example` objects.\n",
        "    training: Boolean indicating if we are in training mode.\n",
        "\n",
        "  Returns:\n",
        "    An instance of `tf.data.TFRecordDataset` containing the `tf.train.Example`\n",
        "    objects.\n",
        "  \"\"\"\n",
        "  dataset = tf.data.TFRecordDataset([file_path])\n",
        "  if training:\n",
        "    dataset = dataset.shuffle(10000)\n",
        "  dataset = dataset.map(parse_example)\n",
        "  dataset = dataset.batch(HPARAMS.batch_size)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "train_dataset = make_dataset(TRAIN_DATA_PATH, training=True)\n",
        "test_dataset = make_dataset(TEST_DATA_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "klnKZ1W71eIt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "1f66f13f-7fec-46d5-b262-a58164da27d3"
      },
      "source": [
        "for feature_batch, label_batch in train_dataset.take(1):\n",
        "  print('Feature list:', list(feature_batch.keys()))\n",
        "  print('Batch of inputs:', feature_batch['words'])\n",
        "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
        "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
        "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
        "  print('Batch of neighbor weights:',\n",
        "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
        "  print('Batch of labels:', label_batch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
            "Batch of inputs: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Batch of neighbor inputs: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Batch of neighbor weights: tf.Tensor(\n",
            "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1.], shape=(128,), dtype=float32)\n",
            "Batch of labels: tf.Tensor(\n",
            "[1 2 3 1 3 6 2 2 0 1 5 2 1 1 3 1 1 3 6 2 3 3 2 2 6 2 4 2 5 2 2 2 5 2 1 1 3\n",
            " 2 2 4 6 5 4 5 2 2 6 2 6 3 3 1 1 2 1 4 6 1 1 6 1 1 0 4 1 2 6 1 0 2 3 3 2 2\n",
            " 1 3 3 3 1 3 5 1 2 1 1 3 3 4 1 3 3 2 1 5 4 2 1 2 0 3 2 6 0 6 5 5 2 5 2 1 6\n",
            " 1 3 2 2 2 2 2 6 5 3 3 5 3 2 3 6 2], shape=(128,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC89PMPF6SSW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "9b8d7ddf-cb14-471d-98e1-0bd29899777e"
      },
      "source": [
        "# peek into test dataset\n",
        "for feature_batch, label_batch in test_dataset.take(1):\n",
        "  print('Feature list:', list(feature_batch.keys()))\n",
        "  print('Batch of inputs:', feature_batch['words'])\n",
        "  nbr_feature_key = '{}{}_{}'.format(NBR_FEATURE_PREFIX, 0, 'words')\n",
        "  nbr_weight_key = '{}{}{}'.format(NBR_FEATURE_PREFIX, 0, NBR_WEIGHT_SUFFIX)\n",
        "  print('Batch of neighbor inputs:', feature_batch[nbr_feature_key])\n",
        "  print('Batch of neighbor weights:',\n",
        "        tf.reshape(feature_batch[nbr_weight_key], [-1]))\n",
        "  print('Batch of labels:', label_batch)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Feature list: ['NL_nbr_0_weight', 'NL_nbr_0_words', 'words']\n",
            "Batch of inputs: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Batch of neighbor inputs: tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(128, 1433), dtype=int64)\n",
            "Batch of neighbor weights: tf.Tensor(\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.], shape=(128,), dtype=float32)\n",
            "Batch of labels: tf.Tensor(\n",
            "[5 2 2 2 1 2 6 3 2 3 6 1 3 6 4 4 2 3 3 0 2 0 5 2 1 0 6 3 6 4 2 2 3 0 4 2 2\n",
            " 2 2 3 2 2 2 0 2 2 2 2 4 2 3 4 0 2 6 2 1 4 2 0 0 1 4 2 6 0 5 2 2 3 2 5 2 5\n",
            " 2 3 2 2 2 2 2 6 6 3 2 4 2 6 3 2 2 6 2 4 2 2 1 3 4 6 0 0 2 4 2 1 3 6 6 2 6\n",
            " 6 6 1 4 6 4 3 6 6 0 0 2 6 2 4 0 0], shape=(128,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uJfwaetq7DK0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model definition\n",
        "## sequential base model\n",
        "def make_mlp_sequential_model(hparams):\n",
        "  \"\"\"Creates a sequential multi-layer perceptron model.\"\"\"\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(\n",
        "      tf.keras.layers.InputLayer(\n",
        "          input_shape=(hparams.max_seq_length,), name='words'))\n",
        "  # Input is already one-hot encoded in the integer format. We cast it to\n",
        "  # floating point format here.\n",
        "  model.add(\n",
        "      tf.keras.layers.Lambda(lambda x: tf.keras.backend.cast(x, tf.float32)))\n",
        "  for num_units in hparams.num_fc_units:\n",
        "    model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
        "    # for sequential models, by default, keras ensures that the dropout layer\n",
        "    # is invoked only during training.\n",
        "    model.add(tf.keras.layers.Dropout(hparams.dropout_rate))\n",
        "  model.add(tf.keras.layers.Dense(hparams.num_classes, activation='softmax'))\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQslNGBx8-Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_mlp_functional_model(hparams):\n",
        "  \"\"\"Creates a functional API-based multi-layer perceptron model.\"\"\"\n",
        "  inputs = tf.keras.Input(\n",
        "      shape=(hparams.max_seq_length,), dtype='int64', name='words')\n",
        "  \n",
        "  # input is already one-hot encoded in the integer format. we cast it to\n",
        "  # floating point format here.\n",
        "  cur_layer = tf.keras.layers.Lambda(\n",
        "      lambda x: tf.keras.backend.cast(x, tf.float32))(inputs)\n",
        "  \n",
        "  for num_units in hparams.num_fc_units:\n",
        "    cur_layer = tf.keras.layers.Dense(num_units, activation='relu')(cur_layer)\n",
        "    # for functional models, by default, keras ensures that the 'dropout' layer\n",
        "    # is invoked only during training.\n",
        "    cur_layer = tf.keras.layers.Dropout(hparams.dropout_rate)(cur_layer)\n",
        "    \n",
        "  outputs = tf.keras.layers.Dense(\n",
        "      hparams.num_classes, activation='softmax')(cur_layer)\n",
        "  \n",
        "  model = tf.keras.Model(inputs, outputs=outputs)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7J0HzeX-H46",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# subclass base model\n",
        "def make_mlp_subclass_model(hparams):\n",
        "  \"\"\"Creates a multi-layer perceptron subclass model in Keras.\"\"\"\n",
        "  \n",
        "  class MLP(tf.keras.Model):\n",
        "    \"\"\"Subclass model defining a multi-layer perceptron.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "      super(MLP, self).__init__()\n",
        "      # input is already one-hot encoded in the integer format. we create a \n",
        "      # layer to cast it to floating point format here.\n",
        "      self.cast_to_float_layer = tf.keras.layers.Lambda(\n",
        "          lambda x: tf.keras.backend.cast(x, tf.float32))\n",
        "      self.dense_layers = [\n",
        "          tf.keras.layer.Dense(num_units, activation='relu')\n",
        "          for num_units in hparams.num_fc_units\n",
        "      ]\n",
        "      self.dropout_layer = tf.keras.layers.Dropout(hparams.dropout_rate)\n",
        "      self.output_layer = tf.keras.layers.Dense(\n",
        "          hparams.num_classes, activation='softmax')\n",
        "      \n",
        "    def call(self, inputs, training=False):\n",
        "      cur_layer = self.cast_to_float_layer(inputs['words'])\n",
        "      for dense_layer in self.dense_layers:\n",
        "        cur_layer = dense_layer(cur_layer)\n",
        "        cur_layer = self.dropout_layer(cur_layer, training=training)\n",
        "      \n",
        "      outputs = self.output_layer(cur_layer)\n",
        "      \n",
        "      return outputs\n",
        "    \n",
        "  return MLP()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRDWcCMa_wE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "c7250080-d655-4342-9e3c-204a6b3a3ed7"
      },
      "source": [
        "# create base model(s)\n",
        "# create a base MLP model using the functional API.\n",
        "# alternatively, you can also create a sequential or subclass base model using\n",
        "# the make_mlp_sequential_model() or make_mlp_subclass_model() functions\n",
        "# respectively, defined above. Note that if a subclass model is used, its\n",
        "# summary cannot be generated until it is built.\n",
        "base_model_tag, base_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)\n",
        "base_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "words (InputLayer)           [(None, 1433)]            0         \n",
            "_________________________________________________________________\n",
            "lambda (Lambda)              (None, 1433)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 50)                71700     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                2550      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 7)                 357       \n",
            "=================================================================\n",
            "Total params: 74,607\n",
            "Trainable params: 74,607\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m_ColNrAWWa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2b429f5c-a42f-4c98-c6d8-d19188c3d07f"
      },
      "source": [
        "# train base MLP model\n",
        "# compile and train the base MLP model\n",
        "base_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "base_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "17/17 [==============================] - 1s 46ms/step - loss: 1.9078 - accuracy: 0.2241\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 1.8327 - accuracy: 0.3072\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1.7368 - accuracy: 0.3267\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 1.6328 - accuracy: 0.3527\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 1.5041 - accuracy: 0.4339\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 1.3736 - accuracy: 0.5160\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 1.2251 - accuracy: 0.5847\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 1.1066 - accuracy: 0.6255\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 1.0009 - accuracy: 0.6650\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.8555 - accuracy: 0.7169\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.7838 - accuracy: 0.7466\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.7223 - accuracy: 0.7684\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.6622 - accuracy: 0.7870\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.5953 - accuracy: 0.8125\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.5360 - accuracy: 0.8362\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.5218 - accuracy: 0.8385\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.4622 - accuracy: 0.8617\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.4535 - accuracy: 0.8659\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.4105 - accuracy: 0.8817\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.3758 - accuracy: 0.8868\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.3684 - accuracy: 0.8868\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.3350 - accuracy: 0.8993\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.3142 - accuracy: 0.9137\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.2653 - accuracy: 0.9318\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.2808 - accuracy: 0.9146\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.2557 - accuracy: 0.9248\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2571 - accuracy: 0.9253\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2415 - accuracy: 0.9336\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.2201 - accuracy: 0.9323\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.2133 - accuracy: 0.9448\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.2030 - accuracy: 0.9392\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1954 - accuracy: 0.9462\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1962 - accuracy: 0.9466\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1764 - accuracy: 0.9545\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1875 - accuracy: 0.9448\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1607 - accuracy: 0.9541\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1478 - accuracy: 0.9652\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1668 - accuracy: 0.9476\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1436 - accuracy: 0.9596\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1492 - accuracy: 0.9606\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.1610 - accuracy: 0.9541\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1366 - accuracy: 0.9633\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1342 - accuracy: 0.9652\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1310 - accuracy: 0.9629\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 0.9619\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1267 - accuracy: 0.9624\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1052 - accuracy: 0.9712\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1130 - accuracy: 0.9680\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9777\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1127 - accuracy: 0.9652\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1010 - accuracy: 0.9735\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0963 - accuracy: 0.9717\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.1179 - accuracy: 0.9638\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0933 - accuracy: 0.9773\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0955 - accuracy: 0.9745\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.1060 - accuracy: 0.9671\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0875 - accuracy: 0.9740\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0835 - accuracy: 0.9791\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0897 - accuracy: 0.9735\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0814 - accuracy: 0.9791\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0802 - accuracy: 0.9759\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0798 - accuracy: 0.9791\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0747 - accuracy: 0.9800\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0860 - accuracy: 0.9745\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0769 - accuracy: 0.9828\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0726 - accuracy: 0.9796\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0711 - accuracy: 0.9810\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0690 - accuracy: 0.9842\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0745 - accuracy: 0.9796\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0760 - accuracy: 0.9777\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0699 - accuracy: 0.9814\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0656 - accuracy: 0.9828\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0730 - accuracy: 0.9773\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0676 - accuracy: 0.9838\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0611 - accuracy: 0.9838\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0687 - accuracy: 0.9819\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0768 - accuracy: 0.9814\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0705 - accuracy: 0.9800\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0691 - accuracy: 0.9773\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 13ms/step - loss: 0.0513 - accuracy: 0.9889\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0598 - accuracy: 0.9856\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0614 - accuracy: 0.9824\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0552 - accuracy: 0.9861\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0653 - accuracy: 0.9805\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 12ms/step - loss: 0.0547 - accuracy: 0.9833\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 14ms/step - loss: 0.0662 - accuracy: 0.9810\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0596 - accuracy: 0.9833\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0433 - accuracy: 0.9898\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0617 - accuracy: 0.9805\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0549 - accuracy: 0.9852\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0549 - accuracy: 0.9819\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0560 - accuracy: 0.9828\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0539 - accuracy: 0.9893\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0537 - accuracy: 0.9828\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0477 - accuracy: 0.9879\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0513 - accuracy: 0.9879\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0486 - accuracy: 0.9842\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 15ms/step - loss: 0.0529 - accuracy: 0.9852\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0514 - accuracy: 0.9852\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0523 - accuracy: 0.9819\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35ef51e9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF-1gRHHAtq4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# evaluate base MLP model\n",
        "# helper function to print evaluation metrics.\n",
        "def print_metrics(model_desc, eval_metrics):\n",
        "  \"\"\"Prints evaluation metrics.\n",
        "  \n",
        "  Args:\n",
        "    model_desc: A description of the model.\n",
        "    eval_metrics: A dictionary mapping metric names to corresponding values. It\n",
        "      must contain the loss and accuracy metrics.\n",
        "  \"\"\"\n",
        "  print('\\n')\n",
        "  print('Eval accuracy for ', model_desc, ': ', eval_metrics['accuracy'])\n",
        "  print('Eval loss for ', model_desc, ': ', eval_metrics['loss'])\n",
        "  if 'graph_loss' in eval_metrics:\n",
        "    print('Eval graph loss for ', model_desc, ': ', eval_metrics['graph_loss'])\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXdNFxL7A_d1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7fd93921-6920-4b37-f4a0-ad99692d0039"
      },
      "source": [
        "eval_results = dict(\n",
        "    zip(base_model.metrics_names,\n",
        "        base_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
        "print_metrics('Base MLP model', eval_results)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 33ms/step - loss: 1.1714 - accuracy: 0.7993\n",
            "\n",
            "\n",
            "Eval accuracy for  Base MLP model :  0.79927665\n",
            "Eval loss for  Base MLP model :  1.1713536560535431\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOaiwbZdYuZB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train MLP model with graph regularization\n",
        "\n",
        "# build a new base MLP model.\n",
        "base_reg_model_tag, base_reg_model = 'FUNCTIONAL', make_mlp_functional_model(HPARAMS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xtQ9KnRZLZS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e6ae101-3d7a-4998-8009-79f07f8d4986"
      },
      "source": [
        "# Wrap the base MLP model with graph regularization.\n",
        "graph_reg_config = nsl.configs.GraphRegConfig(\n",
        "    neighbor_config=nsl.configs.GraphNeighborConfig(\n",
        "        max_neighbors=HPARAMS.num_neighbors),\n",
        "    multiplier=HPARAMS.graph_regularization_multiplier,\n",
        "    distance_config=nsl.configs.DistanceConfig(\n",
        "        distance_type=HPARAMS.distance_type, sum_over_axis=-1))\n",
        "graph_reg_model = nsl.keras.GraphRegularization(base_reg_model,\n",
        "                                                graph_reg_config)\n",
        "graph_reg_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy'])\n",
        "graph_reg_model.fit(train_dataset, epochs=HPARAMS.train_epochs, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/losses/losses_impl.py:121: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "17/17 [==============================] - 2s 120ms/step - loss: 1.9034 - accuracy: 0.2339 - graph_loss: 0.0089\n",
            "Epoch 2/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 1.8112 - accuracy: 0.3095 - graph_loss: 0.0147\n",
            "Epoch 3/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 1.7060 - accuracy: 0.3406 - graph_loss: 0.0306\n",
            "Epoch 4/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 1.5845 - accuracy: 0.3898 - graph_loss: 0.0518\n",
            "Epoch 5/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 1.4772 - accuracy: 0.4710 - graph_loss: 0.0730\n",
            "Epoch 6/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 1.3330 - accuracy: 0.5318 - graph_loss: 0.1114\n",
            "Epoch 7/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 1.2054 - accuracy: 0.5884 - graph_loss: 0.1520\n",
            "Epoch 8/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 1.0832 - accuracy: 0.6510 - graph_loss: 0.1942\n",
            "Epoch 9/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.9759 - accuracy: 0.6900 - graph_loss: 0.2170\n",
            "Epoch 10/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.8781 - accuracy: 0.7244 - graph_loss: 0.2408\n",
            "Epoch 11/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.8248 - accuracy: 0.7494 - graph_loss: 0.2604\n",
            "Epoch 12/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.7180 - accuracy: 0.7884 - graph_loss: 0.2758\n",
            "Epoch 13/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6689 - accuracy: 0.8042 - graph_loss: 0.2783\n",
            "Epoch 14/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6063 - accuracy: 0.8237 - graph_loss: 0.3031\n",
            "Epoch 15/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.5775 - accuracy: 0.8339 - graph_loss: 0.3035\n",
            "Epoch 16/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.5145 - accuracy: 0.8548 - graph_loss: 0.3118\n",
            "Epoch 17/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.4918 - accuracy: 0.8594 - graph_loss: 0.3225\n",
            "Epoch 18/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.4577 - accuracy: 0.8738 - graph_loss: 0.3201\n",
            "Epoch 19/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.4252 - accuracy: 0.8854 - graph_loss: 0.3126\n",
            "Epoch 20/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.4156 - accuracy: 0.8826 - graph_loss: 0.3283\n",
            "Epoch 21/100\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.3747 - accuracy: 0.9039 - graph_loss: 0.3264\n",
            "Epoch 22/100\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.3611 - accuracy: 0.9100 - graph_loss: 0.3298\n",
            "Epoch 23/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.3398 - accuracy: 0.9081 - graph_loss: 0.3341\n",
            "Epoch 24/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.3236 - accuracy: 0.9155 - graph_loss: 0.3269\n",
            "Epoch 25/100\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.2829 - accuracy: 0.9387 - graph_loss: 0.3345\n",
            "Epoch 26/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.2958 - accuracy: 0.9193 - graph_loss: 0.3342\n",
            "Epoch 27/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.2862 - accuracy: 0.9281 - graph_loss: 0.3357\n",
            "Epoch 28/100\n",
            "17/17 [==============================] - 0s 22ms/step - loss: 0.2709 - accuracy: 0.9295 - graph_loss: 0.3260\n",
            "Epoch 29/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.2541 - accuracy: 0.9439 - graph_loss: 0.3441\n",
            "Epoch 30/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.2522 - accuracy: 0.9374 - graph_loss: 0.3305\n",
            "Epoch 31/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.2244 - accuracy: 0.9503 - graph_loss: 0.3365\n",
            "Epoch 32/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.2173 - accuracy: 0.9494 - graph_loss: 0.3381\n",
            "Epoch 33/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.2128 - accuracy: 0.9536 - graph_loss: 0.3370\n",
            "Epoch 34/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.2095 - accuracy: 0.9508 - graph_loss: 0.3427\n",
            "Epoch 35/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.2123 - accuracy: 0.9494 - graph_loss: 0.3419\n",
            "Epoch 36/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.1981 - accuracy: 0.9513 - graph_loss: 0.3408\n",
            "Epoch 37/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.1952 - accuracy: 0.9578 - graph_loss: 0.3527\n",
            "Epoch 38/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.1809 - accuracy: 0.9638 - graph_loss: 0.3264\n",
            "Epoch 39/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1790 - accuracy: 0.9619 - graph_loss: 0.3364\n",
            "Epoch 40/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1710 - accuracy: 0.9661 - graph_loss: 0.3488\n",
            "Epoch 41/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1570 - accuracy: 0.9722 - graph_loss: 0.3282\n",
            "Epoch 42/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1680 - accuracy: 0.9615 - graph_loss: 0.3496\n",
            "Epoch 43/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1597 - accuracy: 0.9661 - graph_loss: 0.3417\n",
            "Epoch 44/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1631 - accuracy: 0.9689 - graph_loss: 0.3435\n",
            "Epoch 45/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1520 - accuracy: 0.9657 - graph_loss: 0.3329\n",
            "Epoch 46/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1617 - accuracy: 0.9671 - graph_loss: 0.3427\n",
            "Epoch 47/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1389 - accuracy: 0.9740 - graph_loss: 0.3374\n",
            "Epoch 48/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1418 - accuracy: 0.9717 - graph_loss: 0.3407\n",
            "Epoch 49/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1331 - accuracy: 0.9763 - graph_loss: 0.3368\n",
            "Epoch 50/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1388 - accuracy: 0.9726 - graph_loss: 0.3498\n",
            "Epoch 51/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1416 - accuracy: 0.9735 - graph_loss: 0.3489\n",
            "Epoch 52/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1396 - accuracy: 0.9731 - graph_loss: 0.3444\n",
            "Epoch 53/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.1261 - accuracy: 0.9740 - graph_loss: 0.3492\n",
            "Epoch 54/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.1293 - accuracy: 0.9768 - graph_loss: 0.3416\n",
            "Epoch 55/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1239 - accuracy: 0.9759 - graph_loss: 0.3396\n",
            "Epoch 56/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1228 - accuracy: 0.9740 - graph_loss: 0.3412\n",
            "Epoch 57/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1249 - accuracy: 0.9759 - graph_loss: 0.3393\n",
            "Epoch 58/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.1178 - accuracy: 0.9754 - graph_loss: 0.3442\n",
            "Epoch 59/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1201 - accuracy: 0.9782 - graph_loss: 0.3277\n",
            "Epoch 60/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.1187 - accuracy: 0.9805 - graph_loss: 0.3408\n",
            "Epoch 61/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1177 - accuracy: 0.9791 - graph_loss: 0.3372\n",
            "Epoch 62/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1148 - accuracy: 0.9805 - graph_loss: 0.3403\n",
            "Epoch 63/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1059 - accuracy: 0.9800 - graph_loss: 0.3450\n",
            "Epoch 64/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1050 - accuracy: 0.9847 - graph_loss: 0.3309\n",
            "Epoch 65/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1123 - accuracy: 0.9768 - graph_loss: 0.3362\n",
            "Epoch 66/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1111 - accuracy: 0.9787 - graph_loss: 0.3416\n",
            "Epoch 67/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1027 - accuracy: 0.9838 - graph_loss: 0.3328\n",
            "Epoch 68/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.1113 - accuracy: 0.9768 - graph_loss: 0.3408\n",
            "Epoch 69/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0949 - accuracy: 0.9856 - graph_loss: 0.3325\n",
            "Epoch 70/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.1042 - accuracy: 0.9828 - graph_loss: 0.3396\n",
            "Epoch 71/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.1009 - accuracy: 0.9805 - graph_loss: 0.3341\n",
            "Epoch 72/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0941 - accuracy: 0.9828 - graph_loss: 0.3395\n",
            "Epoch 73/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0927 - accuracy: 0.9861 - graph_loss: 0.3407\n",
            "Epoch 74/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0981 - accuracy: 0.9805 - graph_loss: 0.3346\n",
            "Epoch 75/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0976 - accuracy: 0.9828 - graph_loss: 0.3300\n",
            "Epoch 76/100\n",
            "17/17 [==============================] - 0s 16ms/step - loss: 0.0897 - accuracy: 0.9847 - graph_loss: 0.3279\n",
            "Epoch 77/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0898 - accuracy: 0.9833 - graph_loss: 0.3366\n",
            "Epoch 78/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0873 - accuracy: 0.9879 - graph_loss: 0.3422\n",
            "Epoch 79/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0943 - accuracy: 0.9875 - graph_loss: 0.3434\n",
            "Epoch 80/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0895 - accuracy: 0.9856 - graph_loss: 0.3407\n",
            "Epoch 81/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0929 - accuracy: 0.9814 - graph_loss: 0.3427\n",
            "Epoch 82/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0894 - accuracy: 0.9847 - graph_loss: 0.3385\n",
            "Epoch 83/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0800 - accuracy: 0.9898 - graph_loss: 0.3393\n",
            "Epoch 84/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.0948 - accuracy: 0.9782 - graph_loss: 0.3357\n",
            "Epoch 85/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0874 - accuracy: 0.9875 - graph_loss: 0.3371\n",
            "Epoch 86/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0858 - accuracy: 0.9842 - graph_loss: 0.3375\n",
            "Epoch 87/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0902 - accuracy: 0.9870 - graph_loss: 0.3398\n",
            "Epoch 88/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0866 - accuracy: 0.9884 - graph_loss: 0.3359\n",
            "Epoch 89/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0798 - accuracy: 0.9898 - graph_loss: 0.3369\n",
            "Epoch 90/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0746 - accuracy: 0.9921 - graph_loss: 0.3373\n",
            "Epoch 91/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0793 - accuracy: 0.9884 - graph_loss: 0.3373\n",
            "Epoch 92/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0775 - accuracy: 0.9870 - graph_loss: 0.3359\n",
            "Epoch 93/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0794 - accuracy: 0.9870 - graph_loss: 0.3374\n",
            "Epoch 94/100\n",
            "17/17 [==============================] - 0s 20ms/step - loss: 0.0837 - accuracy: 0.9865 - graph_loss: 0.3342\n",
            "Epoch 95/100\n",
            "17/17 [==============================] - 0s 19ms/step - loss: 0.0818 - accuracy: 0.9875 - graph_loss: 0.3367\n",
            "Epoch 96/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0823 - accuracy: 0.9898 - graph_loss: 0.3382\n",
            "Epoch 97/100\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.0784 - accuracy: 0.9861 - graph_loss: 0.3307\n",
            "Epoch 98/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0757 - accuracy: 0.9875 - graph_loss: 0.3405\n",
            "Epoch 99/100\n",
            "17/17 [==============================] - 0s 18ms/step - loss: 0.0756 - accuracy: 0.9893 - graph_loss: 0.3342\n",
            "Epoch 100/100\n",
            "17/17 [==============================] - 0s 21ms/step - loss: 0.0781 - accuracy: 0.9852 - graph_loss: 0.3386\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35ee336f60>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RlieX5VZK-u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "4340600c-a243-4154-ddab-d677c296824e"
      },
      "source": [
        "eval_results = dict(\n",
        "    zip(graph_reg_model.metrics_names,\n",
        "        graph_reg_model.evaluate(test_dataset, steps=HPARAMS.eval_steps)))\n",
        "print_metrics('MLP + graph regularization', eval_results)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 75ms/step - loss: 1.1344 - accuracy: 0.8065 - graph_loss: 0.0000e+00\n",
            "\n",
            "\n",
            "Eval accuracy for  MLP + graph regularization :  0.80651\n",
            "Eval loss for  MLP + graph regularization :  1.1343902945518494\n",
            "Eval graph loss for  MLP + graph regularization :  0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkeTMD54ajBk",
        "colab_type": "text"
      },
      "source": [
        "**varying the amount of supervision as well as trying different neural architectures for graph regularization**\n",
        "________________________________"
      ]
    }
  ]
}